---
title: 'CT-DQN: Control-Tutored Deep Reinforcement Learning'
openreview: 2xVDgIMcSG4
abstract: 'One of the major challenges in Deep Reinforcement Learning for control
  is the need for extensive training to learn the policy. Motivated by this, we present
  the design of the Control-Tutored Deep Q-Networks (CT-DQN) algorithm, a Deep Reinforcement
  Learning algorithm that leverages a control tutor, i.e., an exogenous control law,
  to reduce learning time. The tutor can be designed using an approximate model of
  the system, without any assumption about the knowledge of the systemâ€™s dynamics.
  There is no expectation that it will be able to achieve the control objective if
  used stand-alone. During learning, the tutor occasionally suggests an action, thus
  partially guiding exploration. We validate our approach on three scenarios from
  OpenAI Gym: the inverted pendulum, lunar lander, and car racing. We demonstrate
  that CT-DQN is able to achieve better or equivalent data efficiency with respect
  to the classic function approximation solutions.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: de-lellis23a
month: 0
tex_title: 'CT-DQN: Control-Tutored Deep Reinforcement Learning'
firstpage: 941
lastpage: 953
page: 941-953
order: 941
cycles: false
bibtex_author: "{De Lellis}, Francesco and Coraggio, Marco and Russo, Giovanni and
  Musolesi, Mirco and Bernardo, Mario di"
author:
- given: Francesco
  family: De Lellis
- given: Marco
  family: Coraggio
- given: Giovanni
  family: Russo
- given: Mirco
  family: Musolesi
- given: Mario di
  family: Bernardo
date: 2023-06-06
address:
container-title: Proceedings of The 5th Annual Learning for Dynamics and Control Conference
volume: '211'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 6
  - 6
pdf: https://proceedings.mlr.press/v211/de-lellis23a/de-lellis23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
