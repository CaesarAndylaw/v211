---
title: Policy Learning for Active Target Tracking over Continuous $SE(3)$ Trajectories
openreview: 6dp5uz72ql
abstract: This paper proposes a novel \emph{model-based policy gradient algorithm}
  for tracking dynamic targets using a mobile robot, equipped with an onboard sensor
  with a limited field of view. The task is to obtain a continuous control policy
  for the mobile robot to collect sensor measurements that reduce uncertainty in the
  target states, measured by the target distribution entropy. We design a neural network
  control policy with the robot $SE(3)$ pose and the mean vector and information matrix
  of the joint target distribution as inputs and attention layers to handle variable
  numbers of targets. We also derive the gradient of the target entropy with respect
  to the network parameters explicitly, allowing efficient model-based policy gradient
  optimization.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang23a
month: 0
tex_title: Policy Learning for Active Target Tracking over Continuous $SE(3)$ Trajectories
firstpage: 64
lastpage: 75
page: 64-75
order: 64
cycles: false
bibtex_author: Yang, Pengzhi and Koga, Shumon and Asgharivaskasi, Arash and Atanasov,
  Nikolay
author:
- given: Pengzhi
  family: Yang
- given: Shumon
  family: Koga
- given: Arash
  family: Asgharivaskasi
- given: Nikolay
  family: Atanasov
date: 2023-06-06
address:
container-title: Proceedings of The 5th Annual Learning for Dynamics and Control Conference
volume: '211'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 6
  - 6
pdf: https://proceedings.mlr.press/v211/yang23a/yang23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
