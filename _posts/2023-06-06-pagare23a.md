---
title: Full Gradient Deep Reinforcement Learning for Average-Reward Criterion
openreview: mZdCJoeLFd5
abstract: We extend the provably convergent Full Gradient DQN algorithm for discounted
  reward Markov decision processes from Avrachenkov et al. (2021) to average reward
  problems. We experimentally compare widely used RVI Q-Learning with recently proposed
  Differential Q-Learning in the neural function approximation setting with Full Gradient
  DQN and DQN. We also extend this to learn Whittle indices for Markovian restless
  multi-armed bandits. We observe a better convergence rate of the proposed Full Gradient
  variant across different tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: pagare23a
month: 0
tex_title: Full Gradient Deep Reinforcement Learning for Average-Reward Criterion
firstpage: 235
lastpage: 247
page: 235-247
order: 235
cycles: false
bibtex_author: Pagare, Tejas and Borkar, Vivek and Avrachenkov, Konstantin
author:
- given: Tejas
  family: Pagare
- given: Vivek
  family: Borkar
- given: Konstantin
  family: Avrachenkov
date: 2023-06-06
address:
container-title: Proceedings of The 5th Annual Learning for Dynamics and Control Conference
volume: '211'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 6
  - 6
pdf: https://proceedings.mlr.press/v211/pagare23a/pagare23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
