---
title: Lipschitz constant estimation for 1D convolutional neural networks
openreview: 07xwqrUg6JB
abstract: In this work, we propose a dissipativity-based method for Lipschitz constant
  estimation of 1D convolutional neural networks (CNNs). In particular, we analyze
  the dissipativity properties of convolutional, pooling, and fully connected layers
  making use of incremental quadratic constraints for nonlinear activation functions
  and pooling operations. The Lipschitz constant of the concatenation of these mappings
  is then estimated by solving a semidefinite program which we derive from dissipativity
  theory. To make our method as efficient as possible, we exploit the structure of
  convolutional layers by realizing these finite impulse response filters as causal
  dynamical systems in state space and carrying out the dissipativity analysis for
  the state space realizations. The examples we provide show that our Lipschitz bounds
  are advantageous in terms of accuracy and scalability.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: pauli23a
month: 0
tex_title: Lipschitz constant estimation for 1D convolutional neural networks
firstpage: 1321
lastpage: 1332
page: 1321-1332
order: 1321
cycles: false
bibtex_author: Pauli, Patricia and Gramlich, Dennis and Allg\"ower, Frank
author:
- given: Patricia
  family: Pauli
- given: Dennis
  family: Gramlich
- given: Frank
  family: Allg√∂wer
date: 2023-06-06
address:
container-title: Proceedings of The 5th Annual Learning for Dynamics and Control Conference
volume: '211'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 6
  - 6
pdf: https://proceedings.mlr.press/v211/pauli23a/pauli23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
