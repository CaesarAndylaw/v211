---
title: Probabilistic Safeguard for Reinforcement Learning Using Safety Index Guided
  Gaussian Process Models
openreview: pYjhQMwSDWr
abstract: Safety is one of the biggest concerns to applying reinforcement learning
  (RL) to the physical world. In its core part, it is challenging to ensure RL agents
  persistently satisfy a hard state constraint without white-box or black-box dynamics
  models. This paper presents an integrated model learning and safe control framework
  to safeguard any RL agent, where the environment dynamics are learned as Gaussian
  processes. The proposed theory provides (i) a novel method to construct an offline
  dataset for model learning that best achieves safety requirements; (ii) a design
  rule to construct the safety index to ensure the existence of safe control under
  control limits; (iii) a probablistic safety guarantee (i.e. probabilistic forward
  invariance) when the model is learned using the aforementioned dataset. Simulation
  results show that our framework achieves almost zero safety violation on various
  continuous control tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhao23a
month: 0
tex_title: Probabilistic Safeguard for Reinforcement Learning Using Safety Index Guided
  Gaussian Process Models
firstpage: 783
lastpage: 796
page: 783-796
order: 783
cycles: false
bibtex_author: Zhao, Weiye and He, Tairan and Liu, Changliu
author:
- given: Weiye
  family: Zhao
- given: Tairan
  family: He
- given: Changliu
  family: Liu
date: 2023-06-06
address:
container-title: Proceedings of The 5th Annual Learning for Dynamics and Control Conference
volume: '211'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 6
  - 6
pdf: https://proceedings.mlr.press/v211/zhao23a/zhao23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
