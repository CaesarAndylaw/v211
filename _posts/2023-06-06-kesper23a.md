---
title: Toward Multi-Agent Reinforcement Learning for Distributed Event-Triggered Control
openreview: 72th6X8TGn
abstract: Event-triggered communication and control provide high control performance
  in networked control systems without overloading the communication network. However,
  most approaches require precise mathematical models of the system dynamics, which
  may not always be available. Model-free learning of communication and control policies
  provides an alternative. Nevertheless, existing methods typically consider single-agent
  settings. This paper proposes a model-free reinforcement learning algorithm that
  jointly learns resource-aware communication and control policies for distributed
  multi-agent systems from data. We evaluate the algorithm in a high-dimensional and
  nonlinear simulation example and discuss promising avenues for further research.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kesper23a
month: 0
tex_title: Toward Multi-Agent Reinforcement Learning for Distributed Event-Triggered
  Control
firstpage: 1072
lastpage: 1085
page: 1072-1085
order: 1072
cycles: false
bibtex_author: Kesper, Lukas and Trimpe, Sebastian and Baumann, Dominik
author:
- given: Lukas
  family: Kesper
- given: Sebastian
  family: Trimpe
- given: Dominik
  family: Baumann
date: 2023-06-06
address:
container-title: Proceedings of The 5th Annual Learning for Dynamics and Control Conference
volume: '211'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 6
  - 6
pdf: https://proceedings.mlr.press/v211/kesper23a/kesper23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
