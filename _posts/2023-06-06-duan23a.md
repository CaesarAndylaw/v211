---
title: A finite-sample analysis of multi-step temporal difference estimates
openreview: 0ie6l2J9yB
abstract: 'We consider the problem of estimating the value function of an infinite-horizon
  $\gamma$-discounted Markov reward process (MRP). We establish non-asymptotic guarantees
  for a general family of multi-step temporal difference (TD) estimates, including
  canonical $K$-step look-ahead TD for $K = 1, 2, \ldots$ and the TD$(\lambda)$ family
  for $\lambda \in [0,1)$ as special cases. Our bounds capture the dependence of these
  estimates on both the variance as defined by Bellman fluctuations, and the bias
  arising from possible model mis-specification. Our results reveal that the variance
  component shows limited sensitivity to the choice of look-ahead defining the estimator
  itself, while increasing the look-ahead can reduce the bias term. This highlights
  the benefit of using a larger look-ahead: it reduces bias but need not increase
  the variance.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: duan23a
month: 0
tex_title: A finite-sample analysis of multi-step temporal difference estimates
firstpage: 612
lastpage: 624
page: 612-624
order: 612
cycles: false
bibtex_author: Duan, Yaqi and Wainwright, Martin J.
author:
- given: Yaqi
  family: Duan
- given: Martin J.
  family: Wainwright
date: 2023-06-06
address:
container-title: Proceedings of The 5th Annual Learning for Dynamics and Control Conference
volume: '211'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 6
  - 6
pdf: https://proceedings.mlr.press/v211/duan23a/duan23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
